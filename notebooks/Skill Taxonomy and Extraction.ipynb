{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill Taxonomy Builder with Embeddings (Improved Extraction)\n",
    "\n",
    "This notebook helps you:\n",
    "1. Build a taxonomy structure from raw skills\n",
    "2. Generate high-quality variations and abbreviations (with improved filtering)\n",
    "3. Compute and store embeddings efficiently\n",
    "4. Set up NumPy-based similarity search with deduplication and scoring improvements\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install sentence-transformers pandas numpy scikit-learn rapidfuzz pyarrow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from rapidfuzz import fuzz, process\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import re\n",
    "from pathlib import Path\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Check if Ollama is running with mistral:7b model\nimport subprocess\nimport time\n\ndef check_ollama_status():\n    \"\"\"Check if Ollama is running and mistral:7b is available\"\"\"\n    try:\n        # Check if ollama is running\n        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True, timeout=5)\n        if result.returncode != 0:\n            print(\"❌ Ollama is not running\")\n            print(\"   Start it with: ollama serve\")\n            return False\n        \n        # Check if mistral:7b is available\n        if 'mistral:7b' in result.stdout or 'mistral:latest' in result.stdout:\n            print(\"✓ Ollama is running\")\n            print(\"✓ mistral:7b is available\")\n            return True\n        else:\n            print(\"✓ Ollama is running\")\n            print(\"❌ mistral:7b not found\")\n            print(\"   Install it with: ollama pull mistral:7b\")\n            print(\"\\nAvailable models:\")\n            print(result.stdout)\n            return False\n            \n    except subprocess.TimeoutExpired:\n        print(\"❌ Ollama is not responding\")\n        print(\"   Start it with: ollama serve\")\n        return False\n    except FileNotFoundError:\n        print(\"❌ Ollama is not installed\")\n        print(\"   Install from: https://ollama.ai\")\n        return False\n\n# Run the check\nollama_ready = check_ollama_status()\n\nif not ollama_ready:\n    print(\"\\n⚠️  LLM relevance validation will be skipped without Ollama\")\n    print(\"   Skills will still be extracted using semantic similarity\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Build Taxonomy Structure\n",
    "\n",
    "We'll analyze your 35,000 skills to create a hierarchical taxonomy using:\n",
    "- Pattern matching for common categories\n",
    "- Hierarchical clustering based on semantic similarity\n",
    "- Parent-child relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load your skills file\n# Adjust the path and format as needed\ndef load_skills(filepath):\n    \"\"\"\n    Load skills from a text file (one skill per line)\n    Lines starting with # are treated as comments and skipped\n    Returns a pandas DataFrame\n    \"\"\"\n    with open(filepath, 'r', encoding='utf-8') as f:\n        skills = []\n        for line in f:\n            line = line.strip()\n            # Skip empty lines and comments\n            if line and not line.startswith('#'):\n                skills.append(line)\n    \n    df = pd.DataFrame({\n        'skill_id': [f'SKILL_{i:05d}' for i in range(len(skills))],\n        'canonical_name': skills,\n        'normalized_name': [s.lower().strip() for s in skills]\n    })\n    \n    return df\n\n# Load your skills from the data directory\nskills_df = load_skills('../data/skills/skills.txt')\nprint(f\"Loaded {len(skills_df)} skills\")\nskills_df.head()"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category distribution:\n",
      "category\n",
      "General                  31069\n",
      "Programming Languages      665\n",
      "Databases                  436\n",
      "Cloud & DevOps             134\n",
      "Web Development            127\n",
      "Data Science & AI           37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic taxonomy building using keyword patterns\n",
    "def extract_category_from_patterns(skill_name):\n",
    "    \"\"\"\n",
    "    Extract likely category based on common patterns\n",
    "    Customize these patterns based on your domain\n",
    "    \"\"\"\n",
    "    skill_lower = skill_name.lower()\n",
    "    \n",
    "    # Programming languages\n",
    "    prog_langs = ['python', 'java', 'javascript', 'c++', 'ruby', 'go', 'rust', 'php', 'swift']\n",
    "    if any(lang in skill_lower for lang in prog_langs):\n",
    "        return 'Programming Languages'\n",
    "    \n",
    "    # Data Science & ML\n",
    "    ds_keywords = ['machine learning', 'data science', 'deep learning', 'neural network', \n",
    "                   'tensorflow', 'pytorch', 'scikit-learn', 'nlp', 'computer vision']\n",
    "    if any(kw in skill_lower for kw in ds_keywords):\n",
    "        return 'Data Science & AI'\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    cloud_keywords = ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'terraform', 'ci/cd', 'devops']\n",
    "    if any(kw in skill_lower for kw in cloud_keywords):\n",
    "        return 'Cloud & DevOps'\n",
    "    \n",
    "    # Databases\n",
    "    db_keywords = ['sql', 'database', 'postgresql', 'mongodb', 'redis', 'mysql', 'oracle']\n",
    "    if any(kw in skill_lower for kw in db_keywords):\n",
    "        return 'Databases'\n",
    "    \n",
    "    # Web Development\n",
    "    web_keywords = ['html', 'css', 'react', 'angular', 'vue', 'frontend', 'backend', 'web development']\n",
    "    if any(kw in skill_lower for kw in web_keywords):\n",
    "        return 'Web Development'\n",
    "    \n",
    "    # Add more categories as needed\n",
    "    \n",
    "    return 'General'\n",
    "\n",
    "# Apply pattern-based categorization\n",
    "skills_df['category'] = skills_df['canonical_name'].apply(extract_category_from_patterns)\n",
    "\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(skills_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding parent-child relationships...\n",
      "\n",
      "Skills with parents:\n",
      "Found 8698 skills with parent relationships\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_name</th>\n",
       "      <th>parent_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.NET Framework 1</td>\n",
       "      <td>[.NET Framework]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.NET Framework 3</td>\n",
       "      <td>[.NET Framework]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.NET Framework 4</td>\n",
       "      <td>[.NET Framework]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10 Gigabit Ethernet</td>\n",
       "      <td>[Ethernet, Gigabit Ethernet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10-Hour OSHA Construction Card</td>\n",
       "      <td>[Construction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100-Ton Master Captain's License</td>\n",
       "      <td>[Captain's License]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12 Volt Electricity</td>\n",
       "      <td>[Electricity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200-Ton Master Captain's License</td>\n",
       "      <td>[Captain's License]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020 Design Software</td>\n",
       "      <td>[Design Software, Design]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>25-Ton Master Captain's License</td>\n",
       "      <td>[Captain's License]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      canonical_name                 parent_skills\n",
       "4                   .NET Framework 1              [.NET Framework]\n",
       "5                   .NET Framework 3              [.NET Framework]\n",
       "6                   .NET Framework 4              [.NET Framework]\n",
       "12               10 Gigabit Ethernet  [Ethernet, Gigabit Ethernet]\n",
       "14    10-Hour OSHA Construction Card                [Construction]\n",
       "16  100-Ton Master Captain's License           [Captain's License]\n",
       "21               12 Volt Electricity                 [Electricity]\n",
       "25  200-Ton Master Captain's License           [Captain's License]\n",
       "26              2020 Design Software     [Design Software, Design]\n",
       "27   25-Ton Master Captain's License           [Captain's License]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect parent-child relationships\n",
    "def find_parent_skills(skill, all_skills, threshold=0.85):\n",
    "    \"\"\"\n",
    "    Find potential parent skills (broader skills that contain this one)\n",
    "    Example: 'Python Programming' is parent of 'Python Django'\n",
    "    \"\"\"\n",
    "    skill_lower = skill.lower()\n",
    "    parents = []\n",
    "    \n",
    "    for other_skill in all_skills:\n",
    "        if skill == other_skill:\n",
    "            continue\n",
    "            \n",
    "        other_lower = other_skill.lower()\n",
    "        \n",
    "        # Check if skill contains the other (other is more general)\n",
    "        if other_lower in skill_lower and other_lower != skill_lower:\n",
    "            # Check token overlap to avoid false positives\n",
    "            skill_tokens = set(skill_lower.split())\n",
    "            other_tokens = set(other_lower.split())\n",
    "            \n",
    "            if other_tokens.issubset(skill_tokens):\n",
    "                parents.append(other_skill)\n",
    "    \n",
    "    return parents\n",
    "\n",
    "# Find parent relationships (this can take a while for 35k skills)\n",
    "print(\"Finding parent-child relationships...\")\n",
    "all_skill_names = skills_df['canonical_name'].tolist()\n",
    "skills_df['parent_skills'] = skills_df['canonical_name'].apply(\n",
    "    lambda x: find_parent_skills(x, all_skill_names)\n",
    ")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSkills with parents:\")\n",
    "skills_with_parents = skills_df[skills_df['parent_skills'].apply(len) > 0]\n",
    "print(f\"Found {len(skills_with_parents)} skills with parent relationships\")\n",
    "skills_with_parents[['canonical_name', 'parent_skills']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate High-Quality Variations and Abbreviations\n",
    "\n",
    "We'll use a data-driven approach with improved filtering:\n",
    "- Rule-based abbreviation generation\n",
    "- Common typo patterns\n",
    "- Case variations (filtered to avoid false positives)\n",
    "- Token reordering for multi-word skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating variations...\n",
      "\n",
      "Generated 231,869 total variations\n",
      "Average 7.1 variations per skill\n",
      "\n",
      "Example variations:\n",
      "\n",
      "Component Design:\n",
      "  ['Component_Design', 'cd', 'COMPONENT DESIGN', 'Component-Design', 'ComponentD', 'CD', 'component design', 'Design Component']\n",
      "\n",
      "Cloudera Certified Developer For Hadoop (CCDH):\n",
      "  ['CCDH(', 'Cloudera Certified Developer For Hadoop (Ccdh)', 'cloudera certified developer for hadoop (ccdh)', 'Cloudera-Certified-Developer-For-Hadoop-(CCDH)', 'cloudera certifeid developer for hadoop (ccdh)', 'CLOUDERA CERTIFIED DEVELOPER FOR HADOOP (CCDH)', 'cloudera certified developer for hadop (ccdh)', 'cloudera certified developer for hadoop (cdh)', 'Cloudera_Certified_Developer_For_Hadoop_(CCDH)', 'ClouderaCDH(']\n",
      "\n",
      "Registration:\n",
      "  ['registration', 'REGISTRATION']\n",
      "\n",
      "Sonatype:\n",
      "  ['SONATYPE', 'sonatype']\n",
      "\n",
      "Stormwater Monitoring:\n",
      "  ['Stormwater_Monitoring', 'SM', 'Stormwater-Monitoring', 'STORMWATER MONITORING', 'stormwater monitoring', 'sm', 'StormwaterM', 'Monitoring Stormwater']\n"
     ]
    }
   ],
   "source": [
    "def generate_abbreviations(skill_name):\n",
    "    \"\"\"\n",
    "    Generate likely abbreviations using rules\n",
    "    \"\"\"\n",
    "    abbreviations = set()\n",
    "    \n",
    "    # Remove common words that are typically not abbreviated\n",
    "    stopwords = {'and', 'or', 'the', 'of', 'for', 'with', 'in', 'on', 'at'}\n",
    "    \n",
    "    tokens = skill_name.split()\n",
    "    filtered_tokens = [t for t in tokens if t.lower() not in stopwords]\n",
    "    \n",
    "    if len(filtered_tokens) > 1:\n",
    "        # First letter of each word\n",
    "        abbr = ''.join([t[0].upper() for t in filtered_tokens])\n",
    "        abbreviations.add(abbr)\n",
    "        \n",
    "        # First letter lowercase version\n",
    "        abbreviations.add(abbr.lower())\n",
    "        \n",
    "        # Common pattern: First word + first letter of others\n",
    "        if len(filtered_tokens) >= 2:\n",
    "            first_word = filtered_tokens[0]\n",
    "            rest_abbr = ''.join([t[0].upper() for t in filtered_tokens[1:]])\n",
    "            abbreviations.add(f\"{first_word}{rest_abbr}\")\n",
    "    \n",
    "    # Known common abbreviations (add your domain-specific ones)\n",
    "    known_abbrevs = {\n",
    "        'machine learning': ['ML', 'ml'],\n",
    "        'artificial intelligence': ['AI', 'ai'],\n",
    "        'natural language processing': ['NLP', 'nlp'],\n",
    "        'computer vision': ['CV', 'cv'],\n",
    "        'deep learning': ['DL', 'dl'],\n",
    "        'data science': ['DS', 'ds'],\n",
    "        'application programming interface': ['API', 'api'],\n",
    "        'structured query language': ['SQL', 'sql'],\n",
    "        'continuous integration': ['CI', 'ci'],\n",
    "        'continuous deployment': ['CD', 'cd'],\n",
    "    }\n",
    "    \n",
    "    skill_lower = skill_name.lower()\n",
    "    for phrase, abbrevs in known_abbrevs.items():\n",
    "        if phrase in skill_lower:\n",
    "            abbreviations.update(abbrevs)\n",
    "    \n",
    "    return list(abbreviations)\n",
    "\n",
    "def generate_common_typos(skill_name):\n",
    "    \"\"\"\n",
    "    Generate common typo patterns\n",
    "    \"\"\"\n",
    "    typos = set()\n",
    "    skill_lower = skill_name.lower()\n",
    "    \n",
    "    # Common character swaps\n",
    "    swaps = [('ie', 'ei'), ('ph', 'f'), ('tion', 'sion')]\n",
    "    for old, new in swaps:\n",
    "        if old in skill_lower:\n",
    "            typos.add(skill_lower.replace(old, new))\n",
    "    \n",
    "    # Double letter removals (programming -> programing)\n",
    "    for i in range(len(skill_lower) - 1):\n",
    "        if skill_lower[i] == skill_lower[i+1]:\n",
    "            typo = skill_lower[:i] + skill_lower[i+1:]\n",
    "            typos.add(typo)\n",
    "    \n",
    "    return list(typos)\n",
    "\n",
    "def generate_variations(skill_name):\n",
    "    \"\"\"\n",
    "    Generate all variations of a skill with improved filtering\n",
    "    \"\"\"\n",
    "    variations = set()\n",
    "    tokens = skill_name.split()\n",
    "    \n",
    "    # For single-word skills, be more conservative with variations\n",
    "    if len(tokens) == 1:\n",
    "        variations.add(skill_name.lower())\n",
    "        variations.add(skill_name.upper())\n",
    "        # Only add abbreviations for longer technical terms\n",
    "        if len(skill_name) > 4:\n",
    "            variations.update(generate_abbreviations(skill_name))\n",
    "        variations.discard(skill_name)\n",
    "        return list(variations)\n",
    "    \n",
    "    # For multi-word skills, generate full variations\n",
    "    variations.add(skill_name)\n",
    "    variations.add(skill_name.lower())\n",
    "    variations.add(skill_name.upper())\n",
    "    variations.add(skill_name.title())\n",
    "    \n",
    "    # Abbreviations\n",
    "    variations.update(generate_abbreviations(skill_name))\n",
    "    \n",
    "    # Common typos (limit to avoid explosion)\n",
    "    typos = generate_common_typos(skill_name)\n",
    "    variations.update(typos[:5])\n",
    "    \n",
    "    # Token reordering for 2-word skills\n",
    "    if len(tokens) == 2:\n",
    "        variations.add(f\"{tokens[1]} {tokens[0]}\")\n",
    "    \n",
    "    # Hyphen/underscore variations\n",
    "    if ' ' in skill_name:\n",
    "        variations.add(skill_name.replace(' ', '-'))\n",
    "        variations.add(skill_name.replace(' ', '_'))\n",
    "    \n",
    "    # Remove the original to avoid duplication\n",
    "    variations.discard(skill_name)\n",
    "    \n",
    "    # Filter out problematic variations (common words that cause false positives)\n",
    "    common_words = {'project', 'projects', 'management', 'analysis', 'development', \n",
    "                    'design', 'testing', 'planning', 'support', 'systems', 'data',\n",
    "                    'business', 'technical', 'customer', 'service', 'process'}\n",
    "    \n",
    "    filtered_variations = []\n",
    "    for var in variations:\n",
    "        var_lower = var.lower()\n",
    "        # Keep variations that:\n",
    "        # 1. Are not single common words, OR\n",
    "        # 2. Have special characters (hyphens, underscores)\n",
    "        if var_lower not in common_words or ' ' in var or '-' in var or '_' in var:\n",
    "            filtered_variations.append(var)\n",
    "    \n",
    "    return filtered_variations\n",
    "\n",
    "# Generate variations for all skills\n",
    "print(\"Generating variations...\")\n",
    "skills_df['variations'] = skills_df['canonical_name'].apply(generate_variations)\n",
    "\n",
    "# Show statistics\n",
    "avg_variations = skills_df['variations'].apply(len).mean()\n",
    "total_variations = skills_df['variations'].apply(len).sum()\n",
    "print(f\"\\nGenerated {total_variations:,} total variations\")\n",
    "print(f\"Average {avg_variations:.1f} variations per skill\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nExample variations:\")\n",
    "for idx in skills_df.sample(min(5, len(skills_df))).index:\n",
    "    skill = skills_df.loc[idx, 'canonical_name']\n",
    "    vars = skills_df.loc[idx, 'variations']\n",
    "    print(f\"\\n{skill}:\")\n",
    "    print(f\"  {vars[:10]}\")  # Show first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compute and Store Embeddings\n",
    "\n",
    "We'll use sentence-transformers to generate embeddings for:\n",
    "- Canonical skill names\n",
    "- All variations\n",
    "\n",
    "These will be pre-computed and stored for fast loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Model loaded. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "# Options:\n",
    "# - 'all-MiniLM-L6-v2': Fast, good balance (384 dimensions)\n",
    "# - 'multi-qa-MiniLM-L6-cos-v1': Better for asymmetric search\n",
    "# - 'all-mpnet-base-v2': Higher quality, slower (768 dimensions)\n",
    "\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"Model loaded. Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for canonical skill names...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dee630c145349548eebf971317c05e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1015 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 32468 embeddings\n",
      "Embedding shape: (32468, 384)\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings for canonical names\n",
    "print(\"Computing embeddings for canonical skill names...\")\n",
    "canonical_names = skills_df['canonical_name'].tolist()\n",
    "canonical_embeddings = model.encode(\n",
    "    canonical_names,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "# Store embeddings in dataframe\n",
    "skills_df['embedding'] = list(canonical_embeddings)\n",
    "\n",
    "print(f\"Computed {len(canonical_embeddings)} embeddings\")\n",
    "print(f\"Embedding shape: {canonical_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing embeddings for all variations...\n",
      "Total entries (canonical + variations): 264,337\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33c6cddaf0a4882b7dce38d56319adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed 264,337 variation embeddings\n"
     ]
    }
   ],
   "source": [
    "# Create variation-to-skill mapping with embeddings\n",
    "print(\"\\nComputing embeddings for all variations...\")\n",
    "\n",
    "variation_data = []\n",
    "for idx, row in skills_df.iterrows():\n",
    "    skill_id = row['skill_id']\n",
    "    canonical = row['canonical_name']\n",
    "    \n",
    "    # Add canonical name\n",
    "    variation_data.append({\n",
    "        'skill_id': skill_id,\n",
    "        'canonical_name': canonical,\n",
    "        'variation': canonical,\n",
    "        'is_canonical': True\n",
    "    })\n",
    "    \n",
    "    # Add all variations\n",
    "    for var in row['variations']:\n",
    "        variation_data.append({\n",
    "            'skill_id': skill_id,\n",
    "            'canonical_name': canonical,\n",
    "            'variation': var,\n",
    "            'is_canonical': False\n",
    "        })\n",
    "\n",
    "variations_df = pd.DataFrame(variation_data)\n",
    "print(f\"Total entries (canonical + variations): {len(variations_df):,}\")\n",
    "\n",
    "# Compute embeddings for all variations\n",
    "all_variations = variations_df['variation'].tolist()\n",
    "variation_embeddings = model.encode(\n",
    "    all_variations,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "variations_df['embedding'] = list(variation_embeddings)\n",
    "print(f\"\\nComputed {len(variation_embeddings):,} variation embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save the complete taxonomy with embeddings\nprint(\"Saving taxonomy...\")\n\n# Output directory\noutput_dir = '../data/skills'\n\n# Save as Parquet (preserves embeddings)\nskills_df.to_parquet(f'{output_dir}/skill_taxonomy.parquet', index=False)\nvariations_df.to_parquet(f'{output_dir}/skill_variations.parquet', index=False)\n\n# Also save as JSON for human readability (without embeddings)\nskills_json = []\nfor idx, row in skills_df.iterrows():\n    skills_json.append({\n        'skill_id': row['skill_id'],\n        'canonical_name': row['canonical_name'],\n        'category': row['category'],\n        'parent_skills': row['parent_skills'],\n        'variations': row['variations'],\n        # Embeddings excluded from JSON to keep file size reasonable\n    })\n\nwith open(f'{output_dir}/skill_taxonomy.json', 'w', encoding='utf-8') as f:\n    json.dump(skills_json, f, indent=2, ensure_ascii=False)\n\nprint(f\"✓ Saved {output_dir}/skill_taxonomy.parquet (with embeddings)\")\nprint(f\"✓ Saved {output_dir}/skill_variations.parquet (with embeddings)\")\nprint(f\"✓ Saved {output_dir}/skill_taxonomy.json (human-readable, no embeddings)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare NumPy-based Similarity Search\n",
    "\n",
    "Instead of FAISS (which can cause segmentation faults), we'll use NumPy for similarity search.\n",
    "This is stable, portable, and still very fast for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Normalize and save embeddings for similarity search\nprint(\"Preparing embeddings for similarity search...\")\n\n# Output directory\noutput_dir = '../data/skills'\n\n# Normalize canonical embeddings\ncanonical_embeddings_normalized = canonical_embeddings.astype('float32')\ncanonical_embeddings_normalized = canonical_embeddings_normalized / np.linalg.norm(\n    canonical_embeddings_normalized, axis=1, keepdims=True\n)\n\n# Save normalized canonical embeddings\nnp.save(f'{output_dir}/skill_canonical_embeddings.npy', canonical_embeddings_normalized)\nprint(f\"✓ Saved {len(canonical_embeddings_normalized)} canonical embeddings\")\n\n# Normalize variation embeddings\nvariation_embeddings_normalized = variation_embeddings.astype('float32')\nvariation_embeddings_normalized = variation_embeddings_normalized / np.linalg.norm(\n    variation_embeddings_normalized, axis=1, keepdims=True\n)\n\n# Save normalized variation embeddings\nnp.save(f'{output_dir}/skill_variations_embeddings.npy', variation_embeddings_normalized)\nprint(f\"✓ Saved {len(variation_embeddings_normalized)} variation embeddings\")\n\nprint(\"\\n✓ All embeddings saved and ready for fast similarity search!\")\n\n# Cleanup to free memory\ndel canonical_embeddings_normalized\ndel variation_embeddings_normalized\ngc.collect()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Usage: Improved SkillExtractor Class\n",
    "\n",
    "This version includes:\n",
    "- Length-based scoring penalty (prevents partial matches from scoring too high)\n",
    "- Similar skill deduplication (removes redundant results)\n",
    "- Better handling of edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Try to import ollama for LLM validation\ntry:\n    import ollama\n    OLLAMA_AVAILABLE = True\nexcept ImportError:\n    OLLAMA_AVAILABLE = False\n    print(\"Note: Ollama not installed. LLM validation will not be available.\")\n\nclass SkillExtractor:\n    \"\"\"\n    Fast skill extraction using pre-built taxonomy and numpy similarity search\n    with improved scoring and deduplication\n    \"\"\"\n    def __init__(self, \n                 taxonomy_path='../data/skills/skill_taxonomy.parquet',\n                 variations_path='../data/skills/skill_variations.parquet',\n                 canonical_embeddings_path='../data/skills/skill_canonical_embeddings.npy',\n                 variations_embeddings_path='../data/skills/skill_variations_embeddings.npy',\n                 model_name='all-MiniLM-L6-v2'):\n        \n        print(\"Loading skill extractor...\")\n        \n        # Load taxonomy\n        self.skills_df = pd.read_parquet(taxonomy_path)\n        self.variations_df = pd.read_parquet(variations_path)\n        \n        # Load embeddings (numpy arrays)\n        self.canonical_embeddings = np.load(canonical_embeddings_path)\n        self.variations_embeddings = np.load(variations_embeddings_path)\n        \n        # Load embedding model\n        self.model = SentenceTransformer(model_name)\n        \n        print(f\"✓ Loaded {len(self.skills_df)} skills\")\n        print(f\"✓ Loaded {len(self.variations_df)} variations\")\n        print(f\"✓ Ready for extraction\")\n    \n    def extract_from_text(self, text, threshold=0.5, top_k=10, use_variations=True,\n                         deduplicate_similar=True, dedup_threshold=0.85,\n                         apply_length_penalty=True,\n                         validate_relevance=True, context=None,\n                         ollama_model=\"mistral:7b\", relevance_threshold=0.5):\n        \"\"\"\n        Extract skills from text using numpy-based similarity search\n        \n        Args:\n            text: Input text to extract skills from\n            threshold: Minimum similarity threshold (0-1)\n            top_k: Number of top matches to consider per n-gram\n            use_variations: Whether to search variations or just canonical names\n            deduplicate_similar: Remove skills that are very similar to each other\n            dedup_threshold: Similarity threshold for considering skills duplicates\n            apply_length_penalty: Penalize matches where ngram is much shorter than skill\n            validate_relevance: Use LLM to validate skill relevance (default True)\n            context: Context hint for relevance validation (e.g., \"software engineer\")\n            ollama_model: Ollama model for validation (default: mistral:7b)\n            relevance_threshold: Minimum relevance score to keep skill\n        \n        Returns:\n            List of detected skills with similarity scores (and relevance_score if validation enabled)\n        \"\"\"\n        # Generate n-grams from text\n        ngrams = self._generate_ngrams(text, max_n=5)\n        \n        if not ngrams:\n            return []\n        \n        # Encode n-grams\n        ngram_embeddings = self.model.encode(ngrams, convert_to_numpy=True)\n        ngram_embeddings = ngram_embeddings / np.linalg.norm(\n            ngram_embeddings, axis=1, keepdims=True\n        )\n        \n        # Search for matches\n        detected_skills = {}\n        \n        for i, ngram in enumerate(ngrams):\n            query = ngram_embeddings[i:i+1]\n            \n            if use_variations:\n                # Compute cosine similarity with all variations (dot product)\n                similarities = np.dot(self.variations_embeddings, query.T).flatten()\n                \n                # Get top k indices\n                if len(similarities) > top_k:\n                    top_indices = np.argpartition(similarities, -top_k)[-top_k:]\n                    top_indices = top_indices[np.argsort(similarities[top_indices])][::-1]\n                else:\n                    top_indices = np.argsort(similarities)[::-1]\n                \n                for idx in top_indices:\n                    dist = similarities[idx]\n                    if dist >= threshold:\n                        match = self.variations_df.iloc[idx]\n                        skill_id = match['skill_id']\n                        canonical = match['canonical_name']\n                        matched_variation = match['variation']\n                        \n                        # Apply length penalty\n                        if apply_length_penalty:\n                            adjusted_score = self._apply_length_penalty(\n                                dist, ngram, canonical\n                            )\n                        else:\n                            adjusted_score = dist\n                        \n                        # Only update if this is a better match\n                        if skill_id not in detected_skills or adjusted_score > detected_skills[skill_id]['score']:\n                            detected_skills[skill_id] = {\n                                'canonical_name': canonical,\n                                'matched_text': ngram,\n                                'matched_variation': matched_variation,\n                                'score': float(adjusted_score),\n                                'raw_similarity': float(dist)\n                            }\n            else:\n                # Search canonical embeddings\n                similarities = np.dot(self.canonical_embeddings, query.T).flatten()\n                \n                if len(similarities) > top_k:\n                    top_indices = np.argpartition(similarities, -top_k)[-top_k:]\n                    top_indices = top_indices[np.argsort(similarities[top_indices])][::-1]\n                else:\n                    top_indices = np.argsort(similarities)[::-1]\n                \n                for idx in top_indices:\n                    dist = similarities[idx]\n                    if dist >= threshold:\n                        match = self.skills_df.iloc[idx]\n                        skill_id = match['skill_id']\n                        canonical = match['canonical_name']\n                        \n                        # Apply length penalty\n                        if apply_length_penalty:\n                            adjusted_score = self._apply_length_penalty(\n                                dist, ngram, canonical\n                            )\n                        else:\n                            adjusted_score = dist\n                        \n                        if skill_id not in detected_skills or adjusted_score > detected_skills[skill_id]['score']:\n                            detected_skills[skill_id] = {\n                                'canonical_name': canonical,\n                                'matched_text': ngram,\n                                'score': float(adjusted_score),\n                                'raw_similarity': float(dist)\n                            }\n        \n        # Sort by score\n        results = sorted(detected_skills.values(), key=lambda x: x['score'], reverse=True)\n        \n        # Deduplicate similar skills\n        if deduplicate_similar and len(results) > 1:\n            results = self._deduplicate_similar_skills(results, dedup_threshold)\n        \n        # Apply LLM relevance validation if enabled\n        if validate_relevance and results and OLLAMA_AVAILABLE:\n            results = self._validate_relevance_with_llm(\n                text, results, context, ollama_model, relevance_threshold\n            )\n        \n        return results\n    \n    def _apply_length_penalty(self, similarity, ngram, canonical_skill):\n        \"\"\"\n        Apply penalty when matched n-gram is much shorter than the skill name\n        \"\"\"\n        ngram_len = len(ngram.split())\n        skill_len = len(canonical_skill.split())\n        \n        if ngram_len < skill_len:\n            length_penalty = ngram_len / skill_len\n            penalty_factor = max(0.5, length_penalty)\n            adjusted_score = similarity * penalty_factor\n        else:\n            adjusted_score = similarity\n        \n        return adjusted_score\n    \n    def _deduplicate_similar_skills(self, results, threshold=0.85):\n        \"\"\"\n        Remove redundant skills that are very similar to higher-scoring skills\n        \"\"\"\n        if len(results) <= 1:\n            return results\n        \n        skill_names = [r['canonical_name'] for r in results]\n        skill_embeddings = self.model.encode(skill_names, convert_to_numpy=True)\n        skill_embeddings = skill_embeddings / np.linalg.norm(skill_embeddings, axis=1, keepdims=True)\n        \n        keep_indices = []\n        \n        for i in range(len(results)):\n            if i == 0:\n                keep_indices.append(i)\n                continue\n            \n            should_keep = True\n            for j in keep_indices:\n                similarity = np.dot(skill_embeddings[i], skill_embeddings[j])\n                if similarity > threshold:\n                    should_keep = False\n                    break\n            \n            if should_keep:\n                keep_indices.append(i)\n        \n        return [results[i] for i in keep_indices]\n    \n    def _generate_ngrams(self, text, max_n=5):\n        \"\"\"\n        Generate n-grams from text (1 to max_n words)\n        \"\"\"\n        text = re.sub(r'[^a-zA-Z0-9\\s-]', ' ', text)\n        tokens = text.lower().split()\n        \n        ngrams = []\n        for n in range(1, min(max_n + 1, len(tokens) + 1)):\n            for i in range(len(tokens) - n + 1):\n                ngram = ' '.join(tokens[i:i+n])\n                ngrams.append(ngram)\n        \n        return ngrams\n    \n    def _validate_relevance_with_llm(self, text, skills, context=None, \n                                     model=\"mistral:7b\", relevance_threshold=0.5):\n        \"\"\"\n        Use a local LLM via Ollama to validate skill relevance to the text context.\n        \"\"\"\n        if not skills:\n            return skills\n        \n        # Limit to top 30 skills (reduced from 50 to prevent truncation)\n        skills_to_validate = skills[:30]\n        skill_names = [s['canonical_name'] for s in skills_to_validate]\n        \n        # Build context description\n        if context:\n            context_desc = f\" about {context}\"\n        else:\n            context_desc = \"\"\n        \n        # Create prompt with numbered skills for reliable matching\n        skills_list = \"\\n\".join([f\"{i}: {name}\" for i, name in enumerate(skill_names)])\n        \n        prompt = f\"\"\"Rate each skill's relevance to this text{context_desc}:\n\n{text[:1500]}\n\nRate from 0.0 (not relevant/incidental) to 1.0 (core requirement).\n\nSkills:\n{skills_list}\n\nReturn ONLY JSON with skill numbers as keys and scores as values.\nExample: {{\"0\": 0.95, \"1\": 0.1, \"2\": 0.85}}\n\nJSON:\"\"\"\n        \n        try:\n            # Call Ollama\n            response = ollama.generate(\n                model=model,\n                prompt=prompt,\n                options={\n                    \"temperature\": 0,\n                    \"num_predict\": 3500,\n                }\n            )\n            \n            response_text = response['response'].strip()\n            \n            # Parse JSON from response\n            try:\n                start_idx = response_text.find('{')\n                if start_idx != -1:\n                    brace_count = 0\n                    end_idx = start_idx\n                    for i, char in enumerate(response_text[start_idx:], start_idx):\n                        if char == '{':\n                            brace_count += 1\n                        elif char == '}':\n                            brace_count -= 1\n                            if brace_count == 0:\n                                end_idx = i + 1\n                                break\n                    json_str = response_text[start_idx:end_idx]\n                    relevance_scores = json.loads(json_str)\n                else:\n                    print(f\"Warning: No JSON found in LLM response\")\n                    return skills\n            except json.JSONDecodeError as e:\n                print(f\"Warning: Could not parse JSON from LLM response: {e}\")\n                return skills\n            \n            # Apply relevance scores using index-based matching\n            validated_skills = []\n            unmatched_count = 0\n            for i, skill in enumerate(skills_to_validate):\n                # Try to get score by index (as string or int)\n                relevance = None\n                if str(i) in relevance_scores:\n                    relevance = float(relevance_scores[str(i)])\n                elif i in relevance_scores:\n                    relevance = float(relevance_scores[i])\n                \n                if relevance is None:\n                    # Not found - assign low score\n                    relevance = 0.1\n                    unmatched_count += 1\n                \n                skill['relevance_score'] = relevance\n                \n                if relevance >= relevance_threshold:\n                    validated_skills.append(skill)\n            \n            if unmatched_count > 0:\n                print(f\"Note: LLM did not rate {unmatched_count} skills (assigned 0.1)\")\n            \n            validated_skills.sort(key=lambda x: (x.get('relevance_score', 0), x['score']), reverse=True)\n            \n            return validated_skills\n            \n        except Exception as e:\n            print(f\"LLM validation failed: {e}\")\n            return skills"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example usage\nextractor = SkillExtractor()\n\n# Test with sample text\nsample_text = \"\"\"\nI have 5 years of experience in Python programming and machine learning. \nI've worked extensively with TensorFlow and PyTorch for deep learning projects.\nI'm also proficient in SQL databases and cloud platforms like AWS.\n\"\"\"\n\n# Extract skills with LLM relevance validation (default)\ndetected = extractor.extract_from_text(\n    sample_text, \n    threshold=0.6, \n    dedup_threshold=0.85,\n    apply_length_penalty=True,\n    context=\"software engineer resume\"\n)\n\nprint(f\"Detected {len(detected)} skills:\")\nprint(\"-\" * 70)\nfor skill in detected[:15]:\n    relevance = skill.get('relevance_score', 'N/A')\n    rel_str = f\"{relevance:.2f}\" if isinstance(relevance, float) else str(relevance)\n    print(f\"  {skill['canonical_name']:30} | Score: {skill['score']:.2f} | Relevance: {rel_str}\")"
  },
  {
   "cell_type": "code",
   "source": "# Test with marine biologist job description\nmarine_bio_text = '''\nA marine biologist studies marine life and ecosystems to understand and protect them. Job duties include conducting research through fieldwork and laboratory work, collecting and analyzing data, monitoring marine populations, and developing conservation strategies. They also write reports, communicate findings to stakeholders and the public, and may work with government agencies or conservation groups. \n\nCore responsibilities:\n• Conduct research: Study marine organisms, their behavior, life cycles, and interactions with their environment. \n• Fieldwork: Go to marine environments to observe wildlife, collect samples (water, organisms, sediment), and conduct surveys. \n• Laboratory work: Analyze collected samples, conduct experiments, and process data. \n• Data analysis: Interpret findings using statistical software and GIS to understand populations and environments. \n• Conservation and management: Develop and implement programs to protect marine life, restore habitats, and manage ecosystems. \n• Reporting and communication: Write research papers, create reports, and present findings to the public, policymakers, and other scientists. \n\nTypical activities:\n• Monitoring marine animal populations and the effects of human activity. \n• Testing sea creatures for pollutants. \n• Using equipment such as SCUBA gear for fieldwork. \n• Working with government agencies or non-profit organizations on conservation efforts. \n• Writing grant proposals for research funding. \n• Attending conferences to share and learn about scientific advancements. \n'''\n\n# Extract skills with relevance validation\ndetected = extractor.extract_from_text(\n    marine_bio_text, \n    threshold=0.6, \n    dedup_threshold=0.85, \n    apply_length_penalty=True,\n    context=\"marine biologist job description\",\n    relevance_threshold=0.3\n)\n\nprint(f\"Marine Biologist - Detected {len(detected)} relevant skills:\")\nprint(\"-\" * 70)\nfor skill in detected[:20]:\n    relevance = skill.get('relevance_score', 'N/A')\n    rel_str = f\"{relevance:.2f}\" if isinstance(relevance, float) else str(relevance)\n    print(f\"  {skill['canonical_name']:30} | Score: {skill['score']:.2f} | Relevance: {rel_str}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test with product manager job description\nproduct_manager_text = '''\nWe are seeking an experienced Product Manager to lead our product development initiatives. The ideal candidate will drive product strategy, work closely with engineering teams, and deliver exceptional user experiences.\n\nKey Responsibilities:\n• Define product vision, strategy, and roadmap aligned with business objectives\n• Gather and prioritize product requirements from stakeholders and customers\n• Work with UX designers to create intuitive user interfaces and experiences\n• Collaborate with engineering teams to deliver features on time and within scope\n• Analyze market trends, competitive landscape, and customer feedback\n• Define and track key performance indicators (KPIs) and success metrics\n• Lead sprint planning, backlog grooming, and agile ceremonies\n• Communicate product updates to executives, sales teams, and customers\n\nRequirements:\n• 5+ years of product management experience in SaaS or technology companies\n• Strong analytical skills with experience in data-driven decision making\n• Excellent communication and presentation skills\n• Experience with agile methodologies (Scrum, Kanban)\n• Proficiency with product management tools (Jira, Confluence, Figma)\n• MBA or technical degree preferred\n\nBenefits:\n• Competitive salary and equity package\n• Health, dental, and vision insurance\n• 401(k) matching\n• Flexible work arrangements\n'''\n\n# Extract skills with relevance validation\ndetected = extractor.extract_from_text(\n    product_manager_text, \n    threshold=0.6, \n    dedup_threshold=0.85, \n    apply_length_penalty=True,\n    context=\"product manager job description\",\n    relevance_threshold=0.3\n)\n\nprint(f\"Product Manager - Detected {len(detected)} relevant skills:\")\nprint(\"-\" * 70)\nfor skill in detected[:20]:\n    relevance = skill.get('relevance_score', 'N/A')\n    rel_str = f\"{relevance:.2f}\" if isinstance(relevance, float) else str(relevance)\n    print(f\"  {skill['canonical_name']:30} | Score: {skill['score']:.2f} | Relevance: {rel_str}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick test - single skill extraction\ntest_text = \"Looking for a data science expert with machine learning experience\"\nresults = extractor.extract_from_text(\n    test_text, \n    context=\"job requirement\",\n    relevance_threshold=0.3\n)\n\nprint(f\"Quick test - {len(results)} skills found:\")\nprint(\"-\" * 70)\nfor skill in results[:5]:\n    relevance = skill.get('relevance_score', 'N/A')\n    rel_str = f\"{relevance:.2f}\" if isinstance(relevance, float) else str(relevance)\n    print(f\"  {skill['canonical_name']:30} | Score: {skill['score']:.2f} | Relevance: {rel_str}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Improvements\n",
    "\n",
    "### Key Improvements in this version:\n",
    "\n",
    "1. **Better Variation Generation**\n",
    "   - Conservative approach for single-word skills\n",
    "   - Filters out common words that cause false positives\n",
    "   - Reduces noise from generic terms like \"projects\", \"management\", etc.\n",
    "\n",
    "2. **Length-Based Scoring Penalty**\n",
    "   - Prevents partial matches from scoring too high\n",
    "   - E.g., matching \"projects\" to \"Project Management\" gets penalized\n",
    "   - Configurable via `apply_length_penalty` parameter\n",
    "\n",
    "3. **Similar Skill Deduplication**\n",
    "   - Removes redundant results (e.g., \"Machine Learning\" and \"ML\")\n",
    "   - Keeps the highest-scoring match from each cluster\n",
    "   - Configurable via `deduplicate_similar` and `dedup_threshold`\n",
    "\n",
    "4. **Better Diagnostics**\n",
    "   - Returns both adjusted score and raw similarity\n",
    "   - Shows which variation was matched\n",
    "   - Easier to debug and tune thresholds\n",
    "\n",
    "### Tuning Recommendations:\n",
    "\n",
    "- **For higher precision**: Increase `threshold` (e.g., 0.7) and `dedup_threshold` (e.g., 0.9)\n",
    "- **For higher recall**: Decrease `threshold` (e.g., 0.4) and disable length penalty\n",
    "- **For balanced results**: Use defaults (threshold=0.6, dedup_threshold=0.85, length_penalty=True)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Test on your actual text data and adjust thresholds\n",
    "2. Add more common words to the filter list if needed\n",
    "3. Consider adding exact/fuzzy matching as a complement to semantic search\n",
    "4. Evaluate on labeled data to measure precision/recall\n",
    "5. Fine-tune the length penalty formula for your specific use case"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}